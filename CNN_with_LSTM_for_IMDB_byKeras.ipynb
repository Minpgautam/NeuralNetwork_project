{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network\n",
    "# done by keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary library\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential  # this is to build a neural network model using keras\n",
    "from keras.layers import Dense, Dropout, Activation # to create dense dataset.apply dropout rate,\n",
    "# to use activation \n",
    "from keras.layers import Embedding  # for performing word embeddings in keras\n",
    "from keras.layers import LSTM # long short term memory(LSTM) is a specific type of RNN model\n",
    "from keras.layers import Conv1D, MaxPool1D # convolution 1D and maxpooling 1D "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the dataset\n",
    "from keras.datasets import imdb   # this is sample dataset given in keras library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data has text(sentiments or review) and label (binary value i.e. positive or negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "max_features=20000\n",
    "maxlen=100    # don't take more than 100 words (people may have written more than 100 review \n",
    "# sentence which consumes lots of time to process, so take only 100 words for analysis)\n",
    "#\n",
    "embedding_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution\n",
    "kernel_size=5\n",
    "filters=64    # 8x8 filter\n",
    "pool_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM\n",
    "lstm_output_size=70  # max neural output (hidden layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "batch_size=30\n",
    "epochs=2\n",
    "'''\n",
    "Note :\n",
    "batch_size is highly sensitive.\n",
    "only 2 epochs are needed as the dataset is very small\n",
    "'''\n",
    "# we can do more epochs to obtain more accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data .......\n",
      "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 4s 0us/step\n",
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Data .......\")\n",
    "(x_train,y_train),(x_test,y_test)=imdb.load_data(num_words=max_features) # loading data\n",
    "# load the dataset but only keep the top n words(i.e. max_features), zero the rest\n",
    "print(len(x_train),\"train sequences\")\n",
    "print(len(x_test),\"test sequences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x times)\n",
      "x_train shape:  (25000, 100)\n",
      "x_test Shape :  (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "# sequence are not same length so we do padding.\n",
    "# truncate and pad input sequences\n",
    "print(\"Pad sequences (samples x times)\")\n",
    "x_train=sequence.pad_sequences(x_train,maxlen=maxlen)\n",
    "x_test=sequence.pad_sequences(x_test,maxlen=maxlen)\n",
    "print(\"x_train shape: \",x_train.shape)\n",
    "print(\"x_test Shape : \",x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model .....\n"
     ]
    }
   ],
   "source": [
    "print(\"Build model .....\")\n",
    "model= Sequential()     # initialize the model\n",
    "model.add(Embedding(max_features,embedding_size,input_length=maxlen)) #\n",
    "model.add(Dropout(0.25))  # we don't want all neuron to connect to hidden layer,so do dropout\n",
    "\n",
    "# now do convolutional  1 dimensional\n",
    "model.add(Conv1D(filters,\n",
    "                kernel_size,\n",
    "                padding=\"valid\",\n",
    "                activation=\"relu\",\n",
    "                strides=1))\n",
    "# After convolution do maxpooling\n",
    "model.add(MaxPool1D(pool_size=pool_size))\n",
    "model.add(LSTM(lstm_output_size))\n",
    "model.add(Dense(1))    # output is 1 i.e positive or negative . less than 1 is zero\n",
    "model.add(Activation(\"sigmoid\"))  # it is binary problem so use sigmoid\n",
    "# we can do this in one line\n",
    "# model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compile the model\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train...\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/2\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.3855 - acc: 0.8178 - val_loss: 0.3369 - val_acc: 0.8527\n",
      "Epoch 2/2\n",
      "25000/25000 [==============================] - 77s 3ms/step - loss: 0.1947 - acc: 0.9257 - val_loss: 0.3519 - val_acc: 0.8512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160165e9438>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train...\")\n",
    "model.fit(x_train,y_train,\n",
    "         batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 6s 258us/step\n",
      "Test score :   0.351885968233645\n",
      "Test accurary :  0.8511999934911728\n"
     ]
    }
   ],
   "source": [
    "# let see the accuracy and score\n",
    "# Final evaluation of the model\n",
    "score,acc=model.evaluate(x_test,y_test,batch_size=batch_size)\n",
    "print(\"Test score :  \",score)\n",
    "print(\"Test accurary : \",acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.7038166 ],\n",
       "       [0.97548705],\n",
       "       [0.9513949 ],\n",
       "       ...,\n",
       "       [0.08909649],\n",
       "       [0.09484072],\n",
       "       [0.4224007 ]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test  # gives binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can apply filter also\n",
    "import numpy as np\n",
    "np.where(model.predict(x_test)>0.5,1,0)   # if >0.5 then 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
